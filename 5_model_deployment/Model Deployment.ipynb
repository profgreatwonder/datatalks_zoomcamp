{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0fb9db4f",
   "metadata": {},
   "source": [
    "# Evaluation Metrics\n",
    "\n",
    "## 4.1 Overview\n",
    "\n",
    "The fourth week of Machine Learning Zoomcamp is about different metrics to evaluate a binary classifier. These measures include accuracy, confusion table, precision, recall, ROC curves(TPR, FRP, random model, and ideal model), AUROC, and cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0c23f047",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f5e44399",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c8b186f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('customer_data.csv')\n",
    "df.columns = df.columns.str.lower().str.replace(' ', '_')\n",
    "categorical_columns = list(df.dtypes[df.dtypes == 'object'].index)\n",
    "\n",
    "for cell in categorical_columns:\n",
    "    df[cell] = df[cell].str.lower().str.replace(' ', '_')\n",
    "    \n",
    "df.totalcharges = pd.to_numeric(df.totalcharges, errors='coerce')\n",
    "df.totalcharges = df.totalcharges.fillna(0)\n",
    "\n",
    "df.churn = (df.churn == 'yes').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6b869d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full_train, df_test = train_test_split(df, test_size=0.2, random_state=1)\n",
    "df_train, df_val = train_test_split(df_full_train, test_size=0.25, random_state=1)\n",
    "\n",
    "df_train = df_train.reset_index(drop=True)\n",
    "df_val = df_val.reset_index(drop=True)\n",
    "df_test = df_test.reset_index(drop=True)\n",
    "\n",
    "y_train = df_train.churn.values\n",
    "y_val = df_val.churn.values\n",
    "y_test = df_val.churn.values\n",
    "\n",
    "del df_train['churn']\n",
    "del df_val['churn']\n",
    "del df_test['churn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "be142dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical = ['tenure', 'monthlycharges', 'totalcharges']\n",
    "\n",
    "categorical = ['gender', 'seniorcitizen', 'partner', 'dependents', \n",
    "        'phoneservice', 'multiplelines', 'internetservice',\n",
    "       'onlinesecurity', 'onlinebackup', 'deviceprotection', \n",
    "        'techsupport','streamingtv', 'streamingmovies', \n",
    "        'contract', 'paperlessbilling',\n",
    "       'paymentmethod']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "52fc0793",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cdc4f814",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to implement, we have to create a train function\n",
    "\n",
    "def train(df_train, y_train, C=1.0):\n",
    "    dicts = df_train[categorical + numerical].to_dict(orient='records')\n",
    "    \n",
    "    dv = DictVectorizer(sparse=False)\n",
    "    X_train = dv.fit_transform(dicts)\n",
    "    \n",
    "    model = LogisticRegression(C=C, max_iter=1000)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    return dv, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0341e07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(df, dv, model):\n",
    "    dicts = df[categorical + numerical].to_dict(orient='records')\n",
    "    \n",
    "    X = dv.transform(dicts)\n",
    "    y_pred = model.predict_proba(X)[:, 1]\n",
    "    \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "77a665fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# k-fold cross-validation\n",
    "\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "492fba3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C=1.0 0.841 +- 0.008\n"
     ]
    }
   ],
   "source": [
    "n_splits = 5\n",
    "C = 1.0\n",
    "kfold = KFold(n_splits=n_splits, shuffle=True, random_state=1)\n",
    "\n",
    "scores = []\n",
    "\n",
    "for train_idx, val_idx in kfold.split(df_full_train):\n",
    "    df_train = df_full_train.iloc[train_idx]\n",
    "    df_val = df_full_train.iloc[val_idx]\n",
    "\n",
    "    y_train = df_train.churn.values\n",
    "    y_val = df_val.churn.values\n",
    "\n",
    "    dv, model = train(df_train, y_train, C=C)\n",
    "    y_pred = predict(df_val, dv, model)\n",
    "\n",
    "    auc = roc_auc_score(y_val, y_pred)\n",
    "    scores.append(auc)\n",
    "\n",
    "print('C=%s %.3f +- %.3f' % (C, np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6d2171d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8435682269548084,\n",
       " 0.8458337471858032,\n",
       " 0.8311780052177403,\n",
       " 0.8301724275756219,\n",
       " 0.8517774779580183]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5035238731962783"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we train our model once more on C=1.0\n",
    "\n",
    "\n",
    "dv, model = train(df_full_train, df_full_train.churn.values, C=1.0)\n",
    "y_pred = predict(df_test, dv, model)\n",
    "\n",
    "auc = roc_auc_score(y_test, y_pred)\n",
    "auc\n",
    "\n",
    "# the result ought to be 0.8572386167896259"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3afa054a",
   "metadata": {},
   "source": [
    "# Model Deployment\n",
    "\n",
    "## 5.1 Intro/Session Overview\n",
    "\n",
    "In This session we talked about the earlier model we made in chapter 3 for churn prediction. This chapter contains the deployment of the model. If we want to use the model to predict new values without running the code, There's a way to do this. The way to use the model in different machines without running the code, is to deploy the model in a server (run the code and make the model). After deploying the code in a machine used as server we can make some endpoints (using api's) to connect from another machine to the server and predict values.\n",
    "\n",
    "To deploy the model in a server there are some steps:\n",
    "\n",
    "- After training the model save it, to use it for making predictions in future (session 02-pickle).\n",
    "- Make the API endpoints in order to request predictions. (session 03-flask-intro and 04-flask-deployment)\n",
    "- Some other server deployment options (sessions 5 to 9)\n",
    "\n",
    "We train a model in jupyter notebook, then we use the model by saving it to a file(model.bin). We want to load the file from a service e.g. churn service and the model will be inside the service. \n",
    "\n",
    "Say we have another service such as a marketing service that contain all the users. The marketing service can send a request to the churn service with info about the user, then the churn service sends back prediciton to the marketing service and based on the prediction received, the marketing service can decide whether they want to send promotional email with discount prices.\n",
    "\n",
    "We put the churn prediction model into a web service using flask (a framework for creating web services in python). We want to wrap the service in such a way that it does not interfere with other services that we have in our machine. What we want to do is to create a special environment for our python dependencies - for this, we will use `pipenv`. We have another layer for system dependencies, then deploy the container to the cloud\n",
    "\n",
    "![deployment_image](deployment.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd3f5221",
   "metadata": {},
   "source": [
    "## 5.2 Saving and Loading the Model\n",
    "\n",
    "- Saving the model to pickle\n",
    "- Loading the model to pickle\n",
    "- Turning our notebook into a python script\n",
    "\n",
    "\n",
    "### Saving the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bb1a49f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle for saving python objects\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f3bda070",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'model_C=1.0.bin'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# output_file = 'model_C=%s.bin' % C\n",
    "output_file = f'model_C={C}.bin'\n",
    "output_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "250829bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create a file and write to it\n",
    "# f_out = open(output_file, 'wb')\n",
    "\n",
    "# # save our model\n",
    "# pickle.dump((dv, model), f_out)\n",
    "\n",
    "# # close the file\n",
    "# f_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ea9dd941",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using a methodology that ensures that the file is always closed\n",
    "# instead of the cell above, we can rewrite:\n",
    "\n",
    "with open(output_file, 'wb') as f_out:\n",
    "    pickle.dump((dv, model), f_out)\n",
    "    # do stuff\n",
    "# here, once outside the 'with' statement, the file closes\n",
    "# and we can do other things."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee894a7d",
   "metadata": {},
   "source": [
    "### Loading the Model\n",
    "\n",
    "We restarted the kernel so that we can mimick loading the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c75aa70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aeb2a278",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file = 'model_C=10.bin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "199a4180",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we read the file here\n",
    "\n",
    "with open(model_file, 'rb') as f_in:\n",
    "    dv, model = pickle.load(f_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5aef553e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(DictVectorizer(sparse=False), LogisticRegression(max_iter=1000))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dv, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "506ddd6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## a new customer informations\n",
    "customer = {\n",
    "  'customerid': '8879-zkjof',\n",
    "  'gender': 'female',\n",
    "  'seniorcitizen': 0,\n",
    "  'partner': 'no',\n",
    "  'dependents': 'no',\n",
    "  'tenure': 41,\n",
    "  'phoneservice': 'yes',\n",
    "  'multiplelines': 'no',\n",
    "  'internetservice': 'dsl',\n",
    "  'onlinesecurity': 'yes',\n",
    "  'onlinebackup': 'no',\n",
    "  'deviceprotection': 'yes',\n",
    "  'techsupport': 'yes',\n",
    "  'streamingtv': 'yes',\n",
    "  'streamingmovies': 'yes',\n",
    "  'contract': 'one_year',\n",
    "  'paperlessbilling': 'yes',\n",
    "  'paymentmethod': 'bank_transfer_(automatic)',\n",
    "  'monthlycharges': 79.85,\n",
    "  'totalcharges': 3320.75\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25809d91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06224295541445037"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we want to turn the customer above into a feature matrix\n",
    "X = dv.transform([customer])\n",
    "model.predict_proba(X)[0, 1]\n",
    "# the result shows that the customer is going to churn for the value of\n",
    "# 0.6363584152715288 cos the result from the cell is wrong."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23cddf8c",
   "metadata": {},
   "source": [
    "It is not convenient to train a model from jupyter notebook. The best way is to create a python file/script that does the training. We do that by downloading the notebook as a python file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4aeabbf",
   "metadata": {},
   "source": [
    "## 5.3 Web Services: Introduction to Flask\n",
    "\n",
    "Web services are services you communicate with over a network using some protocol. We can use flask for implementing it.\n",
    "\n",
    "In this session, we create a simple service where user sends a `ping` address and it responds with a `pong`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f4339e",
   "metadata": {},
   "source": [
    "## 5.4 Serving the Churn Model with Flask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c540dd6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
