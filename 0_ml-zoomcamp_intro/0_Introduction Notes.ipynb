{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dcfc0dba",
   "metadata": {},
   "source": [
    "# Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcfda612",
   "metadata": {},
   "source": [
    "## 1.1 Introduction to Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa87a40d",
   "metadata": {},
   "source": [
    "ML is a process of extracting patterns from data, which is of two types:\n",
    "\n",
    "- features (information about the object) and\n",
    "- target (property to predict).\n",
    "\n",
    "Therefore, new feature values are presented to the model, and it makes predictions from the learned patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd7a0210",
   "metadata": {},
   "source": [
    "## 1.2 ML vs Rule-Based Systems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72760584",
   "metadata": {},
   "source": [
    "The differences between ML and Rule-Based systems is explained with the example of a spam filter.\n",
    "\n",
    "Traditional Rule-Based systems are based on a set of characteristics (keywords, email length, etc.) that identify an email as spam or not. As spam emails keep changing over time the system needs to be upgraded making the process untractable due to the complexity of code maintenance as the system grows.\n",
    "\n",
    "ML can be used to solve this problem with the following steps:\n",
    "\n",
    "#### 1. Get data\n",
    "Emails from the user's spam folder and inbox gives examples of spam and non-spam.\n",
    "\n",
    "#### 2. Define and calculate features\n",
    "Rules/characteristics from rule-based systems can be used as a starting point to define features for the ML model. The value of the target variable for each email can be defined based on where the email was obtained from (spam folder or inbox).\n",
    "\n",
    "Each email can be encoded (converted) to the values of it's features and target.\n",
    "\n",
    "#### 3. Train and use the model\n",
    "A machine learning algorithm can then be applied to the encoded emails to build a model that can predict whether a new email is spam or not spam. The predictions are probabilities, and to make a decision it is necessary to define a threshold to classify emails as spam or not spam.\n",
    "\n",
    "*N/B*: Models output probabilities. we make a decision from it e.g. if a mail is >= 0.5(50%), then it has a higher probability of being spam. Data + Model = Outcome"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a730f648",
   "metadata": {},
   "source": [
    "## 1.3 Supervised Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a383b08",
   "metadata": {},
   "source": [
    "In Supervised Machine Learning (SML) there are always labels associated with certain features. The model is trained, and then it can make predictions on new features. In this way, the model is taught by certain features and targets.\n",
    "\n",
    "- Feature matrix (X): made of observations or objects (rows) and features (columns). X is a 2 dimensional array (an array of arrays).\n",
    "\n",
    "- Target variable (y): a vector with the target information we want to predict. For each row of X there's a value in y. y is one dimensional array.\n",
    "\n",
    "The model can be represented as a function g that takes the X matrix as a parameter and tries to predict values as close as possible to y targets. The obtention of the g function is what it is called training.\n",
    "\n",
    "When we train a model, we want to make sure that it is as close to y as possible. We achieve this by training the function g (reps our model) that takes in matrix X (reps our features) and produces something that is approximately close to target variable y(reps our target).\n",
    "\n",
    "$$g(X) = y$$\n",
    "\n",
    "Types of SML problems\n",
    "- Regression: the output is a number (car's price)\n",
    "- Classification: the output is a category (spam example).\n",
    "- Binary: there are two categories. Probably the most widely used.\n",
    "- Multiclass problems: there are more than two categories.\n",
    "- Ranking: the output is the big scores associated with certain items. It is applied in recommender systems.\n",
    "\n",
    "In summary, SML is about teaching the model by showing different examples, and the goal is to come up with a function that takes the feature matrix as a parameter and makes predictions as close as possible to the y targets.\n",
    "\n",
    "rows are observations while columns are features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b21074d",
   "metadata": {},
   "source": [
    "##  1.4 CRISP-DM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac230ef",
   "metadata": {},
   "source": [
    "CRISP-DM, which stands for Cross-Industry Standard Process for Data Mining, is an open standard process model that describes common approaches used by data mining experts. It is the most widely-used analytics model. It was conceived in 1996 and became a European Union project under the ESPRIT funding initiative in 1997. The project was led by five companies: Integral Solutions Ltd (ISL), Teradata, Daimler AG, NCR Corporation and OHRA, an insurance company:\n",
    "\n",
    "1. Business understanding: An important question is if do we need ML for the project. The goal of the project has to be measurable. We need to come up with some metrics for measurement. For example, reduce the amount of spam mails by 50%.\n",
    "\n",
    "2. Data understanding: Analyze available data sources, and decide if more data is required.\n",
    "\n",
    "3. Data preparation: Clean data and remove noise applying pipelines, and the data should be converted to a tabular format, so we can put it into ML model. In summary, we clean the data, build pipelines and convert into tabular format.\n",
    "\n",
    "4. Modeling: training Different models and choose the best one. Considering the results of this step, it is proper to decide if is required to add new features or fix data issues.\n",
    "\n",
    "5. Evaluation: Measure how well the model is performing and if it solves the business problem.\n",
    "\n",
    "6. Deployment: Roll out to production to all the users. The *evaluation and deployment* often happen together - online evaluation. We often evaluate models through deployment. In summary, we roll out model to all users, monitor the models and ensure the quality and maintainability.\n",
    "\n",
    "**BDDMED**\n",
    "\n",
    "It is important to consider how well maintainable the project is. In general, ML projects require many iterations.\n",
    "\n",
    "#### Iteration:\n",
    "- Start simple\n",
    "- Learn from the feedback\n",
    "- Improve\n",
    "\n",
    "#### Summary Steps for ML Projects\n",
    "1. Understand the problem\n",
    "2. Collect the data\n",
    "3. Prepare (clean) the data\n",
    "4. Select the features\n",
    "4. Train the model\n",
    "5. Use it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f88a3eb3",
   "metadata": {},
   "source": [
    "## 1.5 Model Selection Process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e3f8d72",
   "metadata": {},
   "source": [
    "### Which model to choose?\n",
    "- Logistic regression\n",
    "- Decision tree\n",
    "- Neural Network\n",
    "- Or many others\n",
    "\n",
    "The validation dataset is not used in training. There are feature matrices and y vectors for both training and validation datasets. The model is fitted with training data, and it is used to predict the y values of the validation feature matrix. Then, the predicted y values (probabilities) are compared with the actual y values.\n",
    "\n",
    "**Multiple comparisons problem (MCP):** just by chance one model can be lucky and obtain good predictions because all of them are probabilistic.\n",
    "\n",
    "The test set can help to avoid the MCP. Obtaining the best model is done with the training and validation datasets, while the test dataset is used for assuring that the proposed best model is the best.\n",
    "\n",
    "Splitting the data into training(60%), validation(20%) and test(20%) data will help solve the MCP problem. You can decide to split into any size of your choice. After splitting, we hide the test data set away. We use the validation set to select the best model. To ensure that it is indeed a good model, we apply it to our test data set\n",
    "\n",
    "**Training Data Set:** we take our X and y and train our model g\n",
    "\n",
    "$$g(X) = y$$\n",
    "\n",
    "**Validation Data Set:** we take our X validation and y validation and then apply g to calculate our accuracy. In this step, we select the best model. e.g, neural network. We only use this part of the dataset for select our model. Instead of throwing it away after validating the model, we can add it to the training dataset to train a new model g. This should be a bit better since it uses more data. We can then check it against the test dataset\n",
    "\n",
    "$$X_v Y_v$$\n",
    "\n",
    "**Test Data Set:** to be sure that the model didn't just get lucky during the validation stage, we apply the selected model to the test data set. We extract our feature matrix X and target variable y from the test data set and do an extra round of validation with the test data set. It helps us to be sure that the chosen model is indeed the best. Say we have 80% accuracy from the validation dataset, then we run it in the test dataset and get 79%, this is reasonably close so it is safe to say that the chosen model is a good one. \n",
    "\n",
    "$$X_t Y_t$$\n",
    "\n",
    "1. Split datasets in training, validation, and test. E.g. 60%, 20% and 20% respectively\n",
    "2. Train the models\n",
    "3. Evaluate the models (apply to the validation set)\n",
    "4. Select the best model\n",
    "5. Apply the best model to the test dataset\n",
    "6. Compare the performance metrics of validation and test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
